\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Linear Regression}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.0.1}}{1}{subsection.1.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.0.2}}{1}{subsection.1.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Predictive Mean:}{4}{theorem.1.0.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Predictive Variance:}{4}{theorem.1.0.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Expand the exponents (quadratic form in $w$).}{5}{theorem.1.0.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Group terms in $w$ and complete the square.}{5}{theorem.1.0.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Identify posterior covariance and mean.}{5}{theorem.1.0.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Simplify using $\lambda =\alpha /\beta $.}{5}{theorem.1.0.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Log-Likelihood and Log-Prior in Bayesian Linear Regression}{5}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Model Setup}{5}{subsection.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Log-Likelihood $\,\log p(\mathbf  {y}\mid \mathbf  {X},\mathbf  {w})$}{5}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Log-Prior $\,\log p(\mathbf  {w})$}{5}{subsection.1.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}MAP Estimation (Posterior Mode)}{5}{subsection.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{1. Probabilistic Model \& Error Function}{7}{theorem.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Derivation of the Closed-Form Solution}{7}{theorem.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{1. Probabilistic Model \& Error Function}{9}{Item.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Error Function in Matrix Form}{9}{Item.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3. Derivation of the Closed-Form Solution}{9}{Item.11}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Linear Discriminative Models}{11}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Discriminative Models for Classification}{14}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Sigmoid Function}{14}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Definition}{14}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Derivative}{14}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Range and bounds}{14}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Symmetry}{14}{subsection.3.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Logistic regression and log-odds}{14}{subsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Interpretation of weights}{14}{subsection.3.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Magnitude.}{14}{subsection.3.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sign.}{14}{subsection.3.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.7}Scaling weights}{14}{subsection.3.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.8}Need for the bias term}{14}{subsection.3.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.9}Compact summary}{14}{subsection.3.1.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Log-Likelihood}{14}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Model}{14}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Likelihood of the dataset}{15}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Log-likelihood}{15}{subsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Equivalent compact (stable) expression}{15}{subsection.3.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Negative log-likelihood (binary cross-entropy)}{15}{subsection.3.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.6}Gradient of the log-likelihood}{15}{subsection.3.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.7}Hessian (optional)}{15}{subsection.3.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.8}Summary}{15}{subsection.3.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Convexity}{15}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Setup: Binary Cross-Entropy / NLL}{15}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Proof via Convex Function Composition}{15}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Matrix Form of the Log-Likelihood}{16}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Setup}{16}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Log-Likelihood (Vector Form)}{16}{subsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Compact Form Using Linear Scores}{16}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Augmented Representation}{16}{subsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Log-Likelihood Limits and Perfect Separability}{16}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Sigmoid Limit Behavior}{16}{subsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Log-Likelihood of a Single Sample}{16}{subsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Limit for Positive Samples}{16}{subsection.3.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Limit for Negative Samples}{16}{subsection.3.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.5}Implication for the Full Log-Likelihood}{16}{subsection.3.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.6}Zero is the Maximum Possible Log-Likelihood}{17}{subsection.3.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.7}Final Summary}{17}{subsection.3.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Gradient of Logistic Regression}{17}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Setup}{17}{subsection.3.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Derivative for a Single Sample}{17}{subsection.3.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Gradients w.r.t. Parameters}{17}{subsection.3.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}Matrix Derivation of the Vector Form}{17}{subsection.3.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.5}Final Vector and Augmented Forms}{17}{subsection.3.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Gradient Descent on Logistic Regression}{17}{section.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}Setup}{17}{subsection.3.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Batch Gradient Descent (BGD)}{18}{subsection.3.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.3}Stochastic Gradient Descent (SGD)}{18}{subsection.3.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.4}Final Quick-Reference Summary}{18}{subsection.3.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Learning Rate Stability}{18}{section.3.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.1}Logistic Loss and Gradient Descent}{18}{subsection.3.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.2}Hessian of the Logistic Loss}{18}{subsection.3.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.3}Stability Condition for Gradient Descent}{19}{subsection.3.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.4}Error Dynamics Near the Optimum}{19}{subsection.3.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.5}Divergence Behavior Specific to Logistic Regression}{19}{subsection.3.8.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.6}Final Summary}{19}{subsection.3.8.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Linearity of Decision Boundary}{19}{section.3.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.1}Binary Logistic Regression}{19}{subsection.3.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.2}Geometric Interpretation}{19}{subsection.3.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.3}Multiclass Extension}{19}{subsection.3.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.4}Summary}{19}{subsection.3.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.10}SVM and Logistic Crossover}{20}{section.3.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.1}Statement of the question}{20}{subsection.3.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.2}1. Exact equality under strong conditions}{20}{subsection.3.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.3}2. Asymptotic / loss-level intuition}{20}{subsection.3.10.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.4}3. Geometric condition (margin alignment)}{20}{subsection.3.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.5}4. When they do \emph  {not} coincide}{20}{subsection.3.10.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.6}5. Compact exam-ready summary}{20}{subsection.3.10.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.11}Failure of Logistic Regression}{20}{section.3.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.11.1}1. When does logistic regression fail (geometric view)?}{20}{subsection.3.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.11.2}2. Collinearity / rank deficiency}{20}{subsection.3.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Geometric implication}{20}{subsection.3.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Mathematical consequences}{20}{subsection.3.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Geometric picture}{21}{subsection.3.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.11.3}3. How regularization fixes these failures}{21}{subsection.3.11.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.11.4}4. Summary}{21}{subsection.3.11.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.12}L2 Regularisation}{21}{section.3.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12.1}1. Loss definition}{21}{subsection.3.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12.2}2. Useful identities}{21}{subsection.3.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12.3}3. Vector gradients}{21}{subsection.3.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12.4}4. Per-sample component form}{21}{subsection.3.12.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12.5}5. Augmented notation (if bias also regularised)}{21}{subsection.3.12.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12.6}6. Final boxed results}{21}{subsection.3.12.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.13}L1 Regularisation and Gradient}{21}{section.3.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.1}1. Loss definition}{21}{subsection.3.13.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.2}2. Gradient of smooth part}{21}{subsection.3.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.3}3. Subgradient of the \(\ell _1\) term}{22}{subsection.3.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.4}4. Subgradient of the full objective (vector form)}{22}{subsection.3.13.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.5}5. Componentwise subgradient (explicit)}{22}{subsection.3.13.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.6}6. Optimality (KKT) conditions}{22}{subsection.3.13.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.7}7. Proximal (ISTA) update — soft-thresholding}{22}{subsection.3.13.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.8}8. Summary (boxed)}{22}{subsection.3.13.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.14}Lambda Tends to Infinity}{22}{section.3.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.14.1}1. L2-Regularised Logistic Regression}{22}{subsection.3.14.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.14.2}2. L1-Regularised Logistic Regression}{22}{subsection.3.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.14.3}3. Unified Result}{23}{subsection.3.14.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.15}Softmax Function and Its Gradient}{23}{section.3.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.15.1}1. Definition}{23}{subsection.3.15.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.15.2}2. Jacobian of Softmax}{23}{subsection.3.15.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.15.3}3. Gradient of Cross-Entropy w.r.t. Logits}{23}{subsection.3.15.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.15.4}4. Gradient in Softmax Regression (Linear Model)}{23}{subsection.3.15.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.15.5}5. Small Worked Example (Gradient Computation)}{23}{subsection.3.15.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 1: Compute softmax.}{23}{subsection.3.15.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 2: Gradient w.r.t.\ logits.}{23}{subsection.3.15.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 3: Gradient w.r.t.\ weights (for this single example).}{23}{subsection.3.15.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Gradient Descent}{24}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Descent}{24}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}1. Gradient Descent as a Descent Method}{24}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}2. Meaning of the Lipschitz Constant \(L\)}{24}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}3. Values of \(L\) in Common ML Models}{24}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(A) Linear Regression}{24}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(B) Logistic Regression}{24}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(C) Softmax Regression}{24}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}4. Importance of \(L\)}{25}{subsection.4.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}5. Summary}{25}{subsection.4.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.6}Convergence for Quadratic Functions}{25}{subsection.4.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.7}Convergence and Hessian}{26}{subsection.4.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Gradient Descent for Linear and Logistic Regression}{27}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Derivation of GD}{27}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Gradient Descent for Linear Regression}{27}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Problem Setup (MSE Objective)}{27}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Gradients}{27}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gradient w.r.t.\ \(w\).}{27}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gradient w.r.t.\ \(b\).}{27}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Batch Gradient Descent (Full Gradient)}{27}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Stochastic Gradient Descent (Per-example)}{27}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Augmented (Bias-Absorbed) Form}{27}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{L\(_2\)-Regularized Variant (Ridge Regression)}{27}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Numerical Notes}{28}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Gradient Descent and Convexity for Logistic Regression}{28}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Model and Loss}{28}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Gradient (Component and Vector Forms)}{28}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Gradient Descent Updates}{28}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Unregularized GD.}{28}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{L\(_2\)-regularized GD.}{28}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Augmented Compact Form.}{28}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Convexity via the Hessian}{28}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Strict Convexity and Degeneracies}{28}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Summary}{29}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Convergence Proof}{29}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Linear (Geometric) Convergence of Gradient Descent}{29}{subsection.5.2.1}\protected@file@percent }
\newlabel{subsec:gd-linear-conv}{{5.2.1}{29}{Linear (Geometric) Convergence of Gradient Descent}{subsection.5.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Assumptions.}{29}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Auxiliary inequalities (standard consequences).}{29}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Distance contraction (main derivation).}{29}{AMS.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Choosing \(\eta \) and contraction factor.}{29}{AMS.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Function-value (suboptimality) decay.}{30}{AMS.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Remarks and sharper constants.}{30}{AMS.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Final concise theorem statement.}{30}{AMS.16}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Support Vector Machines}{31}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Fundamentals and geometry}{31}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Distance From a Point to a Hyperplane}{31}{subsection.6.1.1}\protected@file@percent }
\newlabel{subsec:distance-hyperplane}{{6.1.1}{31}{Distance From a Point to a Hyperplane}{subsection.6.1.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Step 1: Orthogonal projection.}{31}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 2: Parameterization of the projection.}{31}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 3: Enforce that \(x_i^\perp \in H\).}{31}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 4: Compute the distance.}{31}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Final formula.}{31}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Signed distance (SVM geometric margin).}{31}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Scale Invariance and Supporting Hyperplanes}{31}{section.6.2}\protected@file@percent }
\newlabel{sec:scale-invariance}{{6.2}{31}{Scale Invariance and Supporting Hyperplanes}{section.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Margins and Notation}{31}{subsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Functional margin.}{31}{subsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Geometric margin.}{31}{subsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Points at Distance $\Gamma $ from the Hyperplane}{32}{subsection.6.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Scale Invariance of the Hyperplane}{32}{subsection.6.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Normalizing to $\pm 1$}{32}{subsection.6.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.5}Relation to the Geometric Margin}{32}{subsection.6.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.6}Summary}{32}{subsection.6.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.7}Derivation of the SVM Objective (Hard-Margin Primal)}{32}{subsection.6.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Functional margin}{32}{subsection.6.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Geometric margin}{32}{subsection.6.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Original problem}{32}{subsection.6.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.8}Lagrangian and stationarity}{33}{subsection.6.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{w:}{33}{subsection.6.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{b:}{33}{subsection.6.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.9}Dual form of the Lagrangian — derivation}{33}{subsection.6.2.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{KKT Analysis:}{34}{Item.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Dual (hard-margin):}{36}{Item.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{KKT Complementary Slackness:}{36}{Item.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Interpretation:}{36}{Item.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hard-Margin Support Vector Selection Rule:}{36}{Item.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Dual (soft-margin):}{36}{Item.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Key KKT Relations:}{36}{Item.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Soft-margin point categories from KKT:}{36}{AMS.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Soft-Margin Support Vector Selection Rule:}{36}{AMS.28}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Kernels}{38}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{1. Kernels compute dot products in a transformed space.}{38}{chapter.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Kernel = Similarity Measure in Feature Space.}{38}{chapter.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3. Kernel defines the SVM decision boundary.}{38}{chapter.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{4. Kernel implicitly defines the geometry.}{38}{chapter.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Practical Definition:}{38}{chapter.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step-by-step check:}{38}{chapter.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Concise Mercer Test:}{38}{Item.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why this works:}{38}{Item.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(A) SVM Stationarity (Hard/Soft Margin)}{41}{Item.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(B) Kernel Ridge Regression}{41}{Item.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Primal Problem:}{42}{Item.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Apply Theorem:}{42}{Item.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Kernelized Objective:}{42}{Item.34}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Primal Problem:}{42}{Item.34}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Apply Theorem:}{42}{Item.34}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Kernelized Objective:}{42}{Item.36}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Primal Problem:}{42}{Item.36}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Apply Theorem:}{42}{Item.36}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Kernelized Prediction Function:}{42}{Item.36}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Linear SVM}{44}{Item.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Kernel SVM (non-linear kernel)}{45}{Item.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Consequences:}{45}{Item.45}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Consequences:}{45}{Item.45}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{However:}{45}{Item.45}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Practical Summary:}{46}{Item.45}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Setup and Notation:}{46}{Item.45}\protected@file@percent }
\gdef \@abspage@last{47}
